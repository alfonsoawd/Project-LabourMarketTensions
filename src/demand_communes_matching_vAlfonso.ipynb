{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7719790",
   "metadata": {},
   "source": [
    "# 🏙️ Extracting Communes with 5000+ Inhabitants\n",
    "\n",
    "\n",
    "## 📌 Overview\n",
    "This notebook filters a **communes shapefile** to retain only those with **5000+ inhabitants**, preparing data for mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8af426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re # For regular expression\n",
    "import geopandas as gpd # To read geospatial data\n",
    "from pathlib import Path # To set relative paths\n",
    "import unidecode # To standardize strings\n",
    "import py7zr # To unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTING PROJECT'S ROOT DIRECTORY\n",
    "base_folder = Path().resolve()  # CURRENT WORKING DIRECTORY\n",
    "main_folder = base_folder.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING COMMUNES ZIPPED SHAPEFILE\n",
    "seven_zip_path = main_folder / \"data\" / \"shapefiles\" / \"Communes\" / \"communes-20220101.shp.7z\"\n",
    "extract_dir = main_folder / \"data\" / \"shapefiles\" / \"Communes\"\n",
    "\n",
    "with py7zr.SevenZipFile(seven_zip_path, mode='r') as archive:\n",
    "    archive.extractall(path=extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING ALL NECESSARY DIRECTORIES\n",
    "shapefile_path = main_folder / \"data\" / \"shapefiles\" / \"Communes\" / \"communes-20220101.shp\"\n",
    "stmt_path = main_folder / \"data\" / \"2- Formatted Data\" / \"full_stmt_dataset_cleaned.csv\"\n",
    "output_path = main_folder / \"data\" / \"2- Formatted Data\" / \"full_stmt_dataset_cleaned_v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING FILES\n",
    "communes_shp = gpd.read_file(shapefile_path)\n",
    "stmt_df = pd.read_csv(stmt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388840f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORING FILES AND SMALL ADJUSTMENTS\n",
    "communes_shp.rename(columns={\"nom\": \"commune\"}, inplace=True)\n",
    "communes_shp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e295787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORING FILES AND SMALL ADJUSTMENTS\n",
    "stmt_df.rename(columns={\"Commune de plus de 5000 hab\": \"commune_5000\"}, inplace=True)\n",
    "stmt_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370c566",
   "metadata": {},
   "source": [
    "### The objective is to match our \"commune_5000\" column with the \"commune\" column to align geospatial information for future mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d37691",
   "metadata": {},
   "source": [
    "1- STANDARDIZATION OF COMMUNE COLUMN FROM BOTH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3554fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stmt_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply standardization\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m stmt_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommune_5000\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stmt_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommune_5000\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(standardize_commune)\n\u001b[1;32m     12\u001b[0m communes_shp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommune\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m communes_shp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommune\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(standardize_commune)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Merge datasets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stmt_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardization function\n",
    "def standardize_commune(name):\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    name = unidecode.unidecode(name.lower().strip())  # Remove accents & lowercase\n",
    "    name = re.sub(r\"[-'’]\", \" \", name)  # Remove hyphens & apostrophes\n",
    "    name = re.sub(r\"\\bst[ .]\", \"saint \", name)  # Standardize \"St.\" -> \"Saint\"\n",
    "    return name\n",
    "\n",
    "# Apply standardization\n",
    "stmt_df[\"commune_5000\"] = stmt_df[\"commune_5000\"].apply(standardize_commune)\n",
    "communes_shp[\"commune\"] = communes_shp[\"commune\"].apply(standardize_commune)\n",
    "\n",
    "# Merge datasets\n",
    "df_merged = stmt_df.merge(communes_shp, left_on=\"commune_5000\", right_on=\"commune\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77a82e",
   "metadata": {},
   "source": [
    "2- WHICH COMMUNES WERE NOT MATCHED AND WHY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c84594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique unmatched commune names as a list\n",
    "unique_unmatched_communes_list = df_merged.loc[df_merged[\"commune\"].isna(), \"commune_5000\"].drop_duplicates().tolist()\n",
    "\n",
    "# Print the list\n",
    "print(unique_unmatched_communes_list)\n",
    "\n",
    "# Definining a function that tries to find potential match using regex expressions\n",
    "def regex_search(commune_name, commune_list):\n",
    "    pattern = re.sub(r\"\\s+\", \".*\", commune_name)  # Convert spaces to regex wildcard\n",
    "    matches = [c for c in commune_list if re.search(pattern, c, re.IGNORECASE)]\n",
    "    return matches\n",
    "\n",
    "# Check possible regex matches\n",
    "possible_matches = {c: regex_search(c, communes_shp[\"commune\"].tolist()) for c in unique_unmatched_communes_list}\n",
    "\n",
    "# Print potential matches\n",
    "for key, value in possible_matches.items():\n",
    "    if value:\n",
    "        print(f\"🔍 Possible match for '{key}': {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde43f6c",
   "metadata": {},
   "source": [
    "#### Looking online at the unmatched communes, the issue arises because the shapefile dates from 2022, while the dataset is from 2020. Over the years, some communes have merged, extending their names. However, most of these mergers occurred before 2020, yet the STMT data still contains old commune names. A likely explanation is that administrative and employment service records still use these older commune names. While we could attempt to merge communes, for simplicity, we will drop these approximately 40 communes (0.9% of our sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4aa4fa",
   "metadata": {},
   "source": [
    "3- QUICK VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba89eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert into geospatial dataframe\n",
    "gdf = gpd.GeoDataFrame(df_merged, geometry=\"geometry\")\n",
    "\n",
    "# Define approximate bounding box for mainland France & Corsica\n",
    "france_bounds = (-5, 10, 41, 52)  # (xmin, xmax, ymin, ymax)\n",
    "\n",
    "# Filter to keep only polygons within this bounding box\n",
    "gdf_mainland = gdf.cx[france_bounds[0]:france_bounds[1], france_bounds[2]:france_bounds[3]]\n",
    "\n",
    "# Plot with very thin edges\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "gdf_mainland.plot(ax=ax, edgecolor=\"black\", linewidth=0.1, alpha=0.5)\n",
    "\n",
    "# Remove axis labels for cleaner visualization\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Communes with > 5000 habitants in Metropolitan France\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79944449",
   "metadata": {},
   "source": [
    "4- SAVE AND EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING UNNECESSARY COLUMNS FOR SAVING (KEEPING \"WIKIPEDIA\" FOR POTENTIAL REMERGING)\n",
    "df_merged.drop(columns=[\"commune\", \"surf_ha\", \"insee\", \"geometry\"], inplace=True)\n",
    "\n",
    "# EXPORT DATASET \n",
    "df_merged.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
